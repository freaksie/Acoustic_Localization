{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.optimizers import Adam, Adamax, SGD\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten , Input\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import metrics\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import mimetypes\n",
    "import argparse\n",
    "import imutils\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "# TF_ENABLE_ONEDNN_OPTS=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "import tensorflow as tf\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(tf.device('/gpu:0'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file_path=\"/home/neel/Acoustic/Acoustics/data/labels/\"\n",
    "labels=[]\n",
    "for i in os.listdir(label_file_path):\n",
    "    labels.append(i[:-4])\n",
    "dataset=[]\n",
    "for label in labels:\n",
    "    row=[]\n",
    "    file=open(label_file_path+label+\".txt\",\"r\")\n",
    "    label_s=file.read()\n",
    "    label_list=label_s.replace('\\n','').split(\" \")\n",
    "    channel1=\"channel1_\"+label+\".jpg\"\n",
    "    channel2=\"channel2_\"+label+\".jpg\"\n",
    "    row.append(channel1)\n",
    "    row.append(channel2)\n",
    "    for cord in label_list[1:]:\n",
    "        row.append(cord)\n",
    "    dataset.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.to_csv('data/train.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path=\"/home/neel/Acoustic/Acoustics/data\"\n",
    "spectrogram_path=os.path.sep.join([base_path,\"images\"])\n",
    "annots_path=os.path.sep.join([base_path,\"train.csv\"])\n",
    "\n",
    "base_output=\"/home/neel/Acoustic/Acoustics/output\"\n",
    "model_path=os.path.sep.join([base_output,\"detector.h5\"])\n",
    "plot_path=os.path.sep.join([base_output,\"plot.png\"])\n",
    "test_file=os.path.sep.join([base_output,\"test.txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "print(\"[INFO] loading dataset...\")\n",
    "rows = open(annots_path).read().strip().split(\"\\n\")\n",
    "spectrogram=np.empty(((len(rows)),216,216,6), dtype=\"float32\")\n",
    "bounding_box_cords=[]\n",
    "filenames=[]\n",
    "cnt=0\n",
    "for row in rows:\n",
    "    row = row.split(\",\")\n",
    "    (filename1,filename2,startX, startY, endX, endY) = row\n",
    "    imagePath1 = os.path.sep.join([spectrogram_path, filename1])\n",
    "    imagePath2 = os.path.sep.join([spectrogram_path, filename2])\n",
    "    image1 = tf.io.read_file(imagePath1)\n",
    "    image1=tf.image.decode_image(image1,channels=3,dtype=tf.float32) \n",
    "    image1=tf.image.resize(image1,[216,216])\n",
    "    image2 = tf.io.read_file(imagePath2)\n",
    "    image2=tf.image.decode_image(image2,channels=3,dtype=tf.float32) \n",
    "    image2=tf.image.resize(image2,[216,216])\n",
    "    # print(image1.shape)\n",
    "    data=np.concatenate((image1,image2),axis=-1)\n",
    "    spectrogram[cnt]=data / 255.0\n",
    "    cnt+=1\n",
    "    bounding_box_cords.append((startX,startY,endX,endY))\n",
    "    filenames.append([filename1,filename2])\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(example , height, width, rgb*channel) = (316,640,640,3*2)\n",
    "\n",
    "targets = np.array(bounding_box_cords, dtype=\"float32\")\n",
    "print(spectrogram.shape)\n",
    "del bounding_box_cords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = train_test_split(spectrogram, targets, filenames, test_size=0.10,random_state=42)\n",
    "del spectrogram, targets,filenames\n",
    "(trainImages, testImages) = split[:2]\n",
    "(trainTargets, testTargets) = split[2:4]\n",
    "(trainFilenames, testFilenames) = split[4:]\n",
    "\n",
    "# print(\"[INFO] saving testing filenames...\")\n",
    "# f = open(test_file, \"w\")\n",
    "# for i in testFilenames:\n",
    "#     f.write(i[0]+\",\"+i[1])\n",
    "#     f.write(\"\\n\")\n",
    "# # f.write(\"\\n\".join(testFilenames))\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG16(weights=None, include_top=False,input_tensor=Input(shape=(216, 216, 6)))\n",
    "vgg.trainable = False\n",
    "# flatten the max-pooling output of VGG\n",
    "flatten = vgg.output\n",
    "flatten = Flatten()(flatten)\n",
    "# construct a fully-connected layer header to output the predicted\n",
    "# bounding box coordinates\n",
    "bboxHead = Dense(128, activation=\"relu\")(flatten)\n",
    "bboxHead = Dense(64, activation=\"relu\")(bboxHead)\n",
    "bboxHead = Dense(32, activation=\"relu\")(bboxHead)\n",
    "bboxHead = Dense(4, activation=\"sigmoid\")(bboxHead)\n",
    "model = Model(inputs=vgg.input, outputs=bboxHead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.test.is_gpu_available()\n",
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "init_lr=1e-4\n",
    "epoch=50\n",
    "batch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adamax(lr=init_lr)\n",
    "model.compile(loss=tfa.losses.GIoULoss(), optimizer=opt)\n",
    "print(model.summary())\n",
    "# train the network for bounding box regression\n",
    "print(\"[INFO] training bounding box regressor...\")\n",
    "with tf.device(\"/gpu:0\"):\n",
    "\tH = model.fit(\n",
    "\t\ttrainImages, trainTargets,\n",
    "\t\tvalidation_data=(testImages, testTargets),\n",
    "\t\tbatch_size=batch_size,\n",
    "\t\tepochs=epoch,\n",
    "\t\tverbose=1)\n",
    "# print (\"Average Loss: \",loss,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] saving object detector model...\")\n",
    "model.save(model_path, save_format=\"h5\")\n",
    "N = epoch\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"Bounding Box Regression Loss on Training Set\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(plot_path)\n",
    "del testImages,trainImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model(model_path)\n",
    "for img in testFilenames:\n",
    "    imagePath1=os.path.sep.join([spectrogram_path, img[0]])\n",
    "    imagePath2=os.path.sep.join([spectrogram_path, img[1]])\n",
    "    image1 = tf.io.read_file(imagePath1)\n",
    "    image1=tf.image.decode_image(image1,channels=3,dtype=tf.float32) \n",
    "    image1=tf.image.resize(image1,[216,216])\n",
    "    image2 = tf.io.read_file(imagePath2)\n",
    "    image2=tf.image.decode_image(image2,channels=3,dtype=tf.float32) \n",
    "    image2=tf.image.resize(image2,[216,216])\n",
    "    image1 = np.expand_dims(image1, axis=0)\n",
    "    image2 = np.expand_dims(image2, axis=0)\n",
    "    image=np.concatenate((image1,image2),axis=-1)\n",
    "    \n",
    "    print(image.shape)\n",
    "\n",
    "    preds = model.predict(image)[0]\n",
    "    (startX, startY, endX, endY) = preds\n",
    "    # image2 = cv2.imread(os.path.sep.join([\"/home/neel/Acoustic/yolov5_training/img_data/frames\", img[0][9:]]))\n",
    "    # image2 = imutils.resize(image2, width=600)\n",
    "    # (h, w) = image1.shape[:2]\n",
    "    # startX = startX*w\n",
    "    # startY = startY*h\n",
    "    # endX = endX*w\n",
    "    # endY = endY*h\n",
    "    f=open(\"/home/neel/Acoustic/Acoustics/data/labels/\"+img[0][9:-4]+\".txt\")\n",
    "    print(f.read())\n",
    "    print(startX, startY, endX, endY)\n",
    "    # cv2.rectangle(image2, (startX, startY), (endX, endY),(0, 255, 0), 2)\n",
    "\t# # show the output image\n",
    "    # cv2.imwrite(\"/home/neel/Acoustic/Acoustics/output/test_img/\"+img[0], image2)\n",
    "    # cv2.imshow(\"Output\", image2)\n",
    "    # cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:26:10) \n[GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "1e7274ed0f6198f0b80ec6c61f69697cbc6657ab90adeb9c17021c87e139f38f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
