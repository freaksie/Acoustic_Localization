{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from collections import Counter\n",
    "from tensorflow.python.client import device_lib\n",
    "from keras.optimizers import Adam, Adamax, SGD\n",
    "import imutils\n",
    "import tensorflow_addons as tfa\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
    "gpu = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu[0], True)\n",
    "print(gpu)\n",
    "tf.keras.backend.clear_session()\n",
    "TF_ENABLE_ONEDNN_OPTS=0\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(tf.device('/gpu:0'))\n",
    "\n",
    "tf.device('/gpu:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,sample_rate=librosa.load(\"/home/neel/Acoustic/Acoustics/dataset/datachunks/channel1_normal_train107_23.wav\",sr=None)\n",
    "duration_GT= len(_)/sample_rate\n",
    "label_file_path=\"/home/neel/Acoustic/Acoustics/dataset/labels/\"\n",
    "labels=[]\n",
    "for i in os.listdir(label_file_path):\n",
    "    labels.append(i[:-4])\n",
    "dataset=[]\n",
    "for label in labels:\n",
    "    row=[]\n",
    "    file=open(label_file_path+label+\".txt\",\"r\")\n",
    "    label_s=file.read()\n",
    "    label_list=label_s.replace('\\n','').split(\" \")\n",
    "    channel1=\"channel1_\"+label+\".wav\"\n",
    "    channel2=\"channel2_\"+label+\".wav\"\n",
    "    audio,sample_rate=librosa.load(\"dataset/datachunks/\"+channel1,sr=None)\n",
    "    duration = len(audio)/sample_rate\n",
    "    if duration == duration_GT:\n",
    "        row.append(channel1)\n",
    "        row.append(channel2)\n",
    "        for cord in label_list[1:]:\n",
    "            row.append(cord)\n",
    "        X1=float(row[2])\n",
    "        Y1=float(row[3])\n",
    "        X2=float(row[4])\n",
    "        Y2=float(row[5])\n",
    "        row[2]=X1/1440\n",
    "        row[3]=Y1/1080\n",
    "        row[4]=X2/1440\n",
    "        row[5]=Y2/1080\n",
    "        dataset.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.to_csv('dataset/train.csv', header=False, index=False)\n",
    "del dataset, datasets, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path=\"/home/neel/Acoustic/Acoustics/dataset\"\n",
    "audio_path=os.path.sep.join([base_path,\"datachunks\"])\n",
    "annots_path=os.path.sep.join([base_path,\"train.csv\"])\n",
    "\n",
    "base_output=\"/home/neel/Acoustic/Acoustics/output2.0\"\n",
    "model_path=os.path.sep.join([base_output,\"detector.h5\"])\n",
    "plot_path=os.path.sep.join([base_output,\"plot.png\"])\n",
    "test_file=os.path.sep.join([base_output,\"test.txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] loading dataset...\")\n",
    "rows = open(annots_path).read().strip().split(\"\\n\")\n",
    "spectrogram=np.empty(((len(rows)),525,553,2), dtype=\"float32\")\n",
    "bounding_box_cords=[]\n",
    "window_size=int(1048)\n",
    "wd = signal.windows.hamming(window_size)\n",
    "slide_size = int(1)\n",
    "overlap = window_size - slide_size\n",
    "filenames=[]\n",
    "cnt=0\n",
    "for row in rows:\n",
    "    # print(cnt)\n",
    "    row = row.split(\",\")\n",
    "    (filename1,filename2,X, Y, W, H) = row\n",
    "    channel1_Path = os.path.sep.join([audio_path, filename1])\n",
    "    channel2_path = os.path.sep.join([audio_path, filename2])\n",
    "    \n",
    "    channel1,sample_rate=librosa.load(channel1_Path,sr=None)\n",
    "    channel2,sample_rate=librosa.load(channel2_path,sr=None)\n",
    "\n",
    "    # image1 = cv2.imread(imagePath1)\n",
    "    # image2=cv2.imread(imagePath2)\n",
    "    # (h, w) = image1.shape[:2]\n",
    "\n",
    "    # startX = float(startX) / w\n",
    "    # startY = float(startY) / h\n",
    "    # endX = float(endX) / w\n",
    "    # endY = float(endY) / h\n",
    "\n",
    "    frequency,time,spectrum1=signal.spectrogram(channel1,nfft=window_size,fs=sample_rate,window=wd,noverlap=overlap,mode='magnitude')\n",
    "    frequency,time,spectrum2=signal.spectrogram(channel2,nfft=window_size,fs=sample_rate,window=wd,noverlap=overlap,mode='magnitude')\n",
    "\n",
    "    # print(image1.shape)\n",
    "    data=np.stack((spectrum1,spectrum2),axis=-1)\n",
    "    spectrogram[cnt]=data\n",
    "    del data,frequency,time\n",
    "    cnt+=1\n",
    "    bounding_box_cords.append((X, Y, W, H))\n",
    "    filenames.append([filename1,filename2])\n",
    "    # filenames.append(filename1)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = np.array(bounding_box_cords, dtype=\"float32\")\n",
    "\n",
    "del bounding_box_cords,rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(targets.shape)\n",
    "print(spectrogram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = train_test_split(spectrogram, targets, filenames, test_size=0.10,random_state=42)\n",
    "del spectrogram, targets,filenames\n",
    "(trainData, testData) = split[:2]\n",
    "(trainTargets, testTargets) = split[2:4]\n",
    "(trainFilenames, testFilenames) = split[4:]\n",
    "del split\n",
    "\n",
    "print(\"[INFO] saving testing filenames...\")\n",
    "f = open(test_file, \"w\")\n",
    "for i in testFilenames:\n",
    "    f.write(i[0]+\",\"+i[1])\n",
    "    f.write(\"\\n\")\n",
    "# f.write(\"\\n\".join(testFilenames))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LeakyReLU\n",
    "model= tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32,(3,3), padding='valid',strides=2, input_shape=(525,553,2), activation='relu'))\n",
    "# model.add(LeakyReLU(alpha=0.03))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2), padding='valid'))\n",
    "# model.add(tf.keras.layers.Conv2D(32,(3,3), padding='valid',strides=2,activation='relu'))\n",
    "# # model.add(LeakyReLU(alpha=0.03))\n",
    "# model.add(tf.keras.layers.BatchNormalization())\n",
    "# model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2), padding='valid'))\n",
    "# model.add(tf.keras.layers.Conv2D(64,(3,3), padding='valid', strides=2,activation='relu'))\n",
    "# # model.add(LeakyReLU(alpha=0.03))\n",
    "# model.add(tf.keras.layers.BatchNormalization())\n",
    "# model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2), padding='valid'))\n",
    "# model.add(tf.keras.layers.Conv2D(64,(3,3), padding='valid',strides=2,activation='relu'))\n",
    "# # model.add(LeakyReLU(alpha=0.03))\n",
    "# model.add(tf.keras.layers.BatchNormalization())\n",
    "# model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2), padding='relu'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128,activation='relu'))\n",
    "model.add(LeakyReLU(alpha=0.03))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(64,activation='relu'))\n",
    "# model.add(LeakyReLU(alpha=0.03))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(32,activation='relu'))\n",
    "# model.add(LeakyReLU(alpha=0.03))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(4,activation='relu'))\n",
    "# model.add(LeakyReLU(alpha=0.03))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_lr=1e-4\n",
    "\n",
    "epoch=60\n",
    "batch_size=32\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    init_lr,\n",
    "    decay_steps=20,\n",
    "    decay_rate=0.1,\n",
    "    staircase=True)\n",
    "\n",
    "opt = SGD(learning_rate=lr_schedule ,momentum=0.9, )\n",
    "model.compile(\n",
    "  optimizer=opt,\n",
    "  loss='mse',\n",
    "  metrics=['accuracy'],run_eagerly=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "\tH = model.fit(\n",
    "\t\ttrainData, trainTargets,\n",
    "\t\tvalidation_data=(testData, testTargets),\n",
    "\t\tbatch_size=batch_size,\n",
    "\t\tepochs=epoch,\n",
    "\t\tverbose=1)\n",
    "\tprint(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] saving object detector model...\")\n",
    "model.save(model_path, save_format=\"h5\")\n",
    "N = epoch\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_loss\")\n",
    "plt.title(\"Bounding Box Regression MSE on Training Set\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(plot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del spectrum1, spectrum2, trainData, testData, model, trainTargets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('/home/neel/Acoustic/Acoustics/output2.0/detector.h5')\n",
    "for i,img in enumerate(testFilenames):\n",
    "    if i==10:\n",
    "        break\n",
    "    imagePath1=os.path.sep.join([audio_path, img[0]])\n",
    "    imagePath2=os.path.sep.join([audio_path, img[1]])\n",
    "    channel1,sample_rate=librosa.load(imagePath1,sr=None)\n",
    "    channel2,sample_rate=librosa.load(imagePath2,sr=None)\n",
    "    frequency,time,spectrum1=signal.spectrogram(channel1,nfft=window_size,fs=sample_rate,window=wd,noverlap=overlap,mode='magnitude')\n",
    "    frequency,time,spectrum2=signal.spectrogram(channel2,nfft=window_size,fs=sample_rate,window=wd,noverlap=overlap,mode='magnitude')\n",
    "    spectrum1=np.expand_dims(spectrum1,axis=0)\n",
    "    spectrum2=np.expand_dims(spectrum2,axis=0)\n",
    "    image=np.stack((spectrum1,spectrum2),axis=-1)\n",
    "\n",
    "    preds = model.predict(image)[0]\n",
    "    (startX, startY, endX, endY) = preds\n",
    "    print(imagePath1)\n",
    "    # image2 = cv2.imread(os.path.sep.join([\"/home/neel/Acoustic/yolov5_training/img_data/frames\", img[0][9:]]))\n",
    "    # image2 = imutils.resize(image2, width=600)\n",
    "    # (h, w) = image1.shape[:2]\n",
    "    # startX = startX*w\n",
    "    # startY = startY*h\n",
    "    # endX = endX*w\n",
    "    # endY = endY*h\n",
    "    f=open(\"/home/neel/Acoustic/Acoustics/dataset/labels/\"+img[0][9:-4]+\".txt\")\n",
    "    ground_truth=f.read()\n",
    "    print(\"Ground truth: \",ground_truth[1:])\n",
    "    print(\"Predicted: \",startX, startY, endX, endY)\n",
    "    # cv2.rectangle(image2, (startX, startY), (endX, endY),(0, 255, 0), 2)\n",
    "\t# # show the output image\n",
    "    # cv2.imwrite(\"/home/neel/Acoustic/Acoustics/output/test_img/\"+img[0], image2)\n",
    "    # cv2.imshow(\"Output\", image2)\n",
    "    # cv2.waitKey(0)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib import patches\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "fig = plt.figure()\n",
    "channel1,sample_rate=librosa.load(\"/home/neel/Acoustic/Acoustics/dataset/datachunks/channel1_3m_train2_5.wav\",sr=None)\n",
    "channel2,sample_rate=librosa.load(\"/home/neel/Acoustic/Acoustics/dataset/datachunks/channel2_3m_train2_5.wav\",sr=None)\n",
    "frequency,time,spectrum1=signal.spectrogram(channel1,nfft=window_size,fs=sample_rate,window=wd,noverlap=overlap,mode='magnitude')\n",
    "frequency,time,spectrum2=signal.spectrogram(channel2,nfft=window_size,fs=sample_rate,window=wd,noverlap=overlap,mode='magnitude')\n",
    "spectrum1=np.expand_dims(spectrum1,axis=0)\n",
    "spectrum2=np.expand_dims(spectrum2,axis=0)\n",
    "image=np.stack((spectrum1,spectrum2),axis=-1)\n",
    "preds = model.predict(image)[0]\n",
    "(startX, startY, endX, endY) = preds\n",
    "startX,startY,endX, endY=startX*1440,startY*1080, endX*1440, endY*1080\n",
    "width=endX-startX\n",
    "height=endY-startY\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "print(startX,startY,width,height)\n",
    "image = plt.imread('/home/neel/Acoustic/yolov5_training/img_data/frames/3m_train2_5.jpg')\n",
    "plt.imshow(image)\n",
    "rect = patches.Rectangle((startX,startY), width, height, edgecolor='r', facecolor='none')\n",
    "ax.add_patch(rect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:26:10) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e7274ed0f6198f0b80ec6c61f69697cbc6657ab90adeb9c17021c87e139f38f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
