{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from collections import Counter\n",
    "from tensorflow.python.client import device_lib\n",
    "from keras.optimizers import Adam, Adamax, SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import imutils\n",
    "import tensorflow_addons as tfa\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
    "gpu = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu[0], True)\n",
    "print(gpu)\n",
    "tf.keras.backend.clear_session()\n",
    "TF_ENABLE_ONEDNN_OPTS=0\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(tf.device('/gpu:0'))\n",
    "\n",
    "tf.device('/gpu:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path=\"/home/neel/Acoustic/Acoustics/dataset2\"\n",
    "audio_path=os.path.sep.join([base_path,\"datachunks\"])\n",
    "annots_path=os.path.sep.join([base_path,\"train.csv\"])\n",
    "\n",
    "base_output=\"/home/neel/Acoustic/Acoustics/output4.0\"\n",
    "test_file=os.path.sep.join([base_output,\"test.txt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Spectrograms and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] loading dataset...\")\n",
    "rows = open(annots_path).read().strip().split(\"\\n\")\n",
    "spectrogram=np.empty(((len(rows)),257,273,2), dtype=\"float32\")\n",
    "bounding_box_cords=[]\n",
    "window_size=int(512)\n",
    "wd = signal.windows.hamming(window_size)\n",
    "slide_size = int(4)\n",
    "overlap = window_size - slide_size\n",
    "filenames=[]\n",
    "cnt=0\n",
    "for row in rows:\n",
    "    # print(cnt)\n",
    "    row = row.split(\",\")\n",
    "    (filename1,filename2,X1, Y1, X2, Y2) = row\n",
    "    channel1_Path = os.path.sep.join([audio_path, filename1])\n",
    "    channel2_path = os.path.sep.join([audio_path, filename2])\n",
    "    \n",
    "    channel1,sample_rate=librosa.load(channel1_Path,sr=48000)\n",
    "    channel2,sample_rate=librosa.load(channel2_path,sr=48000)\n",
    "\n",
    "    frequency,time,spectrum1=signal.spectrogram(channel1,nfft=window_size,fs=sample_rate,window=wd,noverlap=overlap,mode='magnitude')\n",
    "    frequency,time,spectrum2=signal.spectrogram(channel2,nfft=window_size,fs=sample_rate,window=wd,noverlap=overlap,mode='magnitude')\n",
    "\n",
    "    # print(image1.shape)\n",
    "    data=np.stack((spectrum1,spectrum2),axis=-1)\n",
    "    spectrogram[cnt]=data\n",
    "    del data,frequency,time\n",
    "    cnt+=1\n",
    "    bounding_box_cords.append((X1, Y1, X2, Y2))\n",
    "    filenames.append([filename1,filename2])\n",
    "    # filenames.append(filename1)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min: %.3f, Max: %.3f' % (spectrogram.min(), spectrogram.max()))\n",
    "for i in range(14132):\n",
    "    min=spectrogram[i].min()\n",
    "    max=spectrogram[i].max()\n",
    "    spectrogram[i]= (spectrogram[i]-min)/(max-min)\n",
    "\n",
    "\n",
    "print('Min: %.3f, Max: %.3f' % (spectrogram.min(), spectrogram.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel1,channel2,rows,spectrum1,spectrum2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = np.array(bounding_box_cords, dtype=\"float32\")\n",
    "print(targets.shape)\n",
    "print(spectrogram.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train - Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = train_test_split(spectrogram, targets, filenames, test_size=0.10,random_state=42)\n",
    "del spectrogram, targets, filenames\n",
    "(trainData, testData) = split[:2]\n",
    "(trainTargets, testTargets) = split[2:4]\n",
    "(trainFilenames, testFilenames) = split[4:]\n",
    "del split\n",
    "\n",
    "print(\"[INFO] saving testing filenames...\")\n",
    "f = open(test_file, \"w\")\n",
    "for i in testFilenames:\n",
    "    f.write(i[0]+\",\"+i[1])\n",
    "    f.write(\"\\n\")\n",
    "# f.write(\"\\n\".join(testFilenames))\n",
    "f.close()\n",
    "\n",
    "print(\"Training examples: \",trainData.shape)\n",
    "print(\"Testing examples: \",testData.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg():\n",
    "    model = tf.keras.Sequential()\n",
    "    # Block 1\n",
    "    model.add(tf.keras.layers.Conv2D(64,(3,3), activation='relu', padding='same', name=\"block1_conv1\", input_shape=(257,273,2)))\n",
    "    model.add(tf.keras.layers.Conv2D(64,(3,3), activation='relu', padding='same', name=\"block1_conv2\"))\n",
    "    model.add(tf.keras.layers.MaxPool2D((2,2), strides=(2,2), name='block1_pool'))\n",
    "\n",
    "    # Block 2\n",
    "    model.add(tf.keras.layers.Conv2D(128,(3,3), activation='relu', padding='same', name=\"block2_conv1\"))\n",
    "    model.add(tf.keras.layers.Conv2D(128,(3,3), activation='relu', padding='same', name=\"block2_conv2\"))\n",
    "    model.add(tf.keras.layers.MaxPool2D((2,2), strides=(2,2), name='block2_pool'))\n",
    "\n",
    "    # Block 3\n",
    "    model.add(tf.keras.layers.Conv2D(256,(3,3), activation='relu', padding='same', name=\"block3_conv1\"))\n",
    "    model.add(tf.keras.layers.Conv2D(256,(3,3), activation='relu', padding='same', name=\"block3_conv2\"))\n",
    "    model.add(tf.keras.layers.Conv2D(256,(3,3), activation='relu', padding='same', name=\"block3_conv3\"))\n",
    "    model.add(tf.keras.layers.MaxPool2D((2,2), strides=(2,2), name='block3_pool'))\n",
    "\n",
    "    # Block 4\n",
    "    model.add(tf.keras.layers.Conv2D(512,(3,3), activation='relu', padding='same', name=\"block4_conv1\"))\n",
    "    model.add(tf.keras.layers.Conv2D(512,(3,3), activation='relu', padding='same', name=\"block4_conv2\"))\n",
    "    model.add(tf.keras.layers.Conv2D(512,(3,3), activation='relu', padding='same', name=\"block4_conv3\"))\n",
    "    model.add(tf.keras.layers.MaxPool2D((2,2), strides=(2,2), name='block4_pool'))\n",
    "\n",
    "    # Block 5\n",
    "    model.add(tf.keras.layers.Conv2D(512,(3,3), activation='relu', padding='same', name=\"block5_conv1\"))\n",
    "    model.add(tf.keras.layers.Conv2D(512,(3,3), activation='relu', padding='same', name=\"block5_conv2\"))\n",
    "    model.add(tf.keras.layers.Conv2D(512,(3,3), activation='relu', padding='same', name=\"block5_conv3\"))\n",
    "    model.add(tf.keras.layers.MaxPool2D((2,2), strides=(2,2), name='block5_pool'))\n",
    "\n",
    "    # FC \n",
    "    model.add(tf.keras.layers.Flatten(name='flatten'))\n",
    "    model.add(tf.keras.layers.Dense(4096, activation='relu', name='fc_1'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5, name='dropout_1'))\n",
    "    model.add(tf.keras.layers.Dense(4096, activation='relu', name='fc_2'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5, name='dropout_2'))\n",
    "    model.add(tf.keras.layers.Dense(1024, activation='relu', name='fc_3'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5, name='dropout_3'))\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu', name='fc_4'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5, name='dropout_4'))\n",
    "\n",
    "    # Output\n",
    "    model.add(tf.keras.layers.Dense(4, activation='relu', name='output'))\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "model=vgg()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(140322,)))\n",
    "    model.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(4, activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "# model=ANN()\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cnn to dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_dense():\n",
    "    model= tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(32,(3,3), padding='valid',strides=2, input_shape=(257,273,2), activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPool2D((2,2), strides=(2,2)))\n",
    "    model.add(tf.keras.layers.Conv2D(32,(3,3), padding='valid',strides=2,activation='relu'))\n",
    "    \n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPool2D((2,2), strides=(2,2)))\n",
    "    model.add(tf.keras.layers.Conv2D(64,(3,3), padding='valid', strides=2,activation='relu'))\n",
    "    \n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPool2D((2,2), strides=(2,2)))\n",
    "    model.add(tf.keras.layers.Conv2D(64,(3,3), padding='valid',strides=2,activation='relu'))\n",
    "    \n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(128,activation='relu'))\n",
    "    \n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(64,activation='relu'))\n",
    "   \n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(32,activation='relu'))\n",
    "   \n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(4,activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "cnn_dense().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN to Dense 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_dense_2():\n",
    "    model= tf.keras.Sequential()\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(32,(3,3), padding='valid',strides=2, input_shape=(257,273,2), activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPool2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(32,(3,3), padding='valid',strides=2,activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPool2D((2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(64,(3,3), padding='valid', strides=2,activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPool2D((2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(64,(3,3), padding='valid',strides=2,activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    \n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(128,activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(128,activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "   \n",
    "    model.add(tf.keras.layers.Dense(64,activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "   \n",
    "    model.add(tf.keras.layers.Dense(32,activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(4,activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# cnn_dense_2().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def l2_loss_func(y_true, y_pred):\n",
    "#   return K.mean(K.square(y_pred - y_true))\n",
    "\n",
    "\n",
    "def iou_loss_func(y_true, y_pred):\n",
    "  # Convert the predicted and ground truth bounding boxes to a format\n",
    "  # suitable for calculating the IOU\n",
    "  y_true = tf.convert_to_tensor(y_true, dtype=tf.float32)\n",
    "  y_pred = tf.convert_to_tensor(y_pred, dtype=tf.float32)\n",
    "\n",
    "  # Calculate the IOU between the predicted and ground truth bounding boxes\n",
    "  x1_true, y1_true, x2_true, y2_true = tf.split(y_true, 4, axis=-1)\n",
    "  x1_pred, y1_pred, x2_pred, y2_pred = tf.split(y_pred, 4, axis=-1)\n",
    "  x1_true, x2_true, x1_pred, x2_pred= x1_true*1920 , x2_true*1920, x1_pred*1920, x2_pred*1920\n",
    "  y1_true, y2_true, y1_pred, y2_pred= y1_true*1080 , y2_true*1080, y1_pred*1080, y2_pred*1080\n",
    "  area_true = (x2_true - x1_true + 1) * (y2_true - y1_true + 1)\n",
    "  area_pred = (x2_pred - x1_pred + 1) * (y2_pred - y1_pred + 1)\n",
    "  x1_true = K.maximum(x1_true, x1_pred)\n",
    "  y1_true = K.maximum(y1_true, y1_pred)\n",
    "  x2_true = K.minimum(x2_true, x2_pred)\n",
    "  y2_true = K.minimum(y2_true, y2_pred)\n",
    "  intersection = K.maximum(0.0, x2_true - x1_true + 1) * K.maximum(0.0, y2_true - y1_true + 1)\n",
    " \n",
    "  iou = intersection / (area_true + area_pred - intersection)\n",
    "  return 1-iou\n",
    "\n",
    "# def GIoU_loss_func(y_true, y_pred):\n",
    "#   # Convert the predicted and ground truth bounding boxes to a format\n",
    "#   # suitable for calculating the IOU\n",
    "#   y_true = tf.convert_to_tensor(y_true, dtype=tf.float32)\n",
    "#   y_pred = tf.convert_to_tensor(y_pred, dtype=tf.float32)\n",
    "\n",
    "#   # Calculate the IOU between the predicted and ground truth bounding boxes\n",
    "#   x1_true, y1_true, x2_true, y2_true = tf.split(y_true, 4, axis=-1)\n",
    "#   x1_pred, y1_pred, x2_pred, y2_pred = tf.split(y_pred, 4, axis=-1)\n",
    "\n",
    "#   x1_true, x2_true, x1_pred, x2_pred= x1_true*1440 , x2_true*1440, x1_pred*1440, x2_pred*1440\n",
    "#   y1_true, y2_true, y1_pred, y2_pred= y1_true*1080 , y2_true*1080, y1_pred*1080, y2_pred*1080\n",
    "\n",
    "#   xmin_enclosing = K.minimum(x1_true, x1_pred)\n",
    "#   ymin_enclosing = K.minimum(y1_true, y1_pred)\n",
    "#   xmax_enclosing = K.maximum(x2_true, x2_pred)\n",
    "#   ymax_enclosing = K.maximum(y2_true, y2_pred)\n",
    "#   area_enclosing = (xmax_enclosing - xmin_enclosing) * (ymax_enclosing - ymin_enclosing)\n",
    "#   # Area of boxes\n",
    "#   area_true = (x2_true - x1_true + 1) * (y2_true - y1_true + 1)\n",
    "#   area_pred = (x2_pred - x1_pred + 1) * (y2_pred - y1_pred + 1)\n",
    "\n",
    "#   x1_true = K.maximum(x1_true, x1_pred)\n",
    "#   y1_true = K.maximum(y1_true, y1_pred)\n",
    "#   x2_true = K.minimum(x2_true, x2_pred)\n",
    "#   y2_true = K.minimum(y2_true, y2_pred)\n",
    "#   intersection = K.maximum(0.0, x2_true - x1_true + 1) * K.maximum(0.0, y2_true - y1_true + 1)\n",
    "  \n",
    "#   # IoU\n",
    "#   iou = intersection / (area_true + area_pred - intersection)\n",
    "#   # calculate GIoU loss\n",
    "#   giou = K.maximum(1.0 - intersection / (area_true + area_pred - intersection) - (area_enclosing - (area_true + area_pred - intersection)) / area_enclosing, 0.0)\n",
    "  \n",
    "#   return K.mean(giou)\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "  # Calculate the Smooth L1 loss and IOU loss\n",
    "  # l2_loss = l2_loss_func(y_true, y_pred)\n",
    "  iou_loss = iou_loss_func(y_true, y_pred)\n",
    "  # giou_loss = GIoU_loss_func(y_true,y_pred)\n",
    "  # Combine the losses with a weight\n",
    "  loss =  1 * iou_loss   #+ 0 * l2_loss \n",
    "  return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_average_precision(y_true, y_pred):\n",
    "    y_true = tf.convert_to_tensor(y_true, dtype=tf.float32)\n",
    "    y_pred = tf.convert_to_tensor(y_pred, dtype=tf.float32)\n",
    "    \n",
    "    # Calculate Intersection Over Union (IOU) for each pair of true and pred boxes\n",
    "    \n",
    "    iou = -(iou_loss_func(y_true,y_pred)-1)\n",
    "    # Set the threshold for considering a prediction as a true positive\n",
    "    threshold = 0.60\n",
    "    \n",
    "    # Find the highest IOU for each true box\n",
    "    best_iou = K.max(iou, axis=-1)\n",
    "    \n",
    "    # Find all predictions with IOU greater than the threshold\n",
    "    true_positive = K.greater(iou, threshold)\n",
    "    hit = tf.reduce_sum(tf.cast(true_positive, tf.float32))\n",
    "    # Find the average precision for all true boxes\n",
    "    precision = []\n",
    "    for t in np.arange(0.5, 0.9, 0.05):\n",
    "        true_positive_at_t = K.cast(K.greater(best_iou, t), dtype='float32')\n",
    "        precision.append(K.mean(true_positive_at_t))\n",
    "    len = tf.shape(true_positive)\n",
    "    length = tf.cast(len[0], tf.float32)\n",
    "    return K.mean(K.stack(precision))*100\n",
    "    # return (hit/length*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_lr=1e-4\n",
    "epoch=9000\n",
    "batch_size=32\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    init_lr,\n",
    "    decay_steps=10,\n",
    "    decay_rate=0.1,\n",
    "    staircase=True)\n",
    "opt = SGD(learning_rate=lr_schedule ,momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VGG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=vgg()\n",
    "model.compile(optimizer=opt, loss=combined_loss, metrics=['Accuracy'] )\n",
    "with tf.device(\"/gpu:0\"):\n",
    "\tH = model.fit(\n",
    "\t\ttrainData, trainTargets,\n",
    "\t\tvalidation_data=(testData, testTargets),\n",
    "\t\tbatch_size=batch_size,\n",
    "\t\tepochs=epoch,\n",
    "\t\tverbose=1)\n",
    "\tprint(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] saving object detector model...\")\n",
    "model.save(base_output+\"/vgg.h5\", save_format=\"h5\")\n",
    "N = epoch\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"Accuracy\"], label=\"train_loss\")\n",
    "plt.title(\"Bounding Box Regression MSE on Training Set\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(base_output+\"/vgg.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData1=trainData.reshape(trainData.shape[0],-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ANN()\n",
    "model.compile(optimizer='adam', loss=tfa.losses.GIoULoss(), metrics=['Accuracy'] )\n",
    "with tf.device(\"/gpu:0\"):\n",
    "\tH = model.fit(\n",
    "\t\ttrainData1, trainTargets,\n",
    "\t\tbatch_size=batch_size,\n",
    "\t\tepochs=epoch,\n",
    "\t\tverbose=1)\n",
    "\tprint(H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] saving object detector model...\")\n",
    "model.save(base_output+\"/ann.h5\", save_format=\"h5\")\n",
    "N = epoch\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"Accuracy\"], label=\"train_loss\")\n",
    "plt.title(\"Bounding Box Regression MSE on Training Set\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(base_output+\"/ann.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN DENSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=cnn_dense()\n",
    "model.compile(optimizer='adam', loss=combined_loss, metrics=[mean_average_precision] )\n",
    "# model_path=base_output+\"/model/cnn_new_9000-{epoch:02d}-{val_loss:.4f}.h5\"\n",
    "# checkpoint = ModelCheckpoint(model_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "# callbacks_list = [checkpoint]\n",
    "with tf.device(\"/gpu:0\"):\n",
    "\tH = model.fit(\n",
    "\t\ttrainData, trainTargets,\n",
    "\t\tvalidation_data=(testData, testTargets),\n",
    "\t\tbatch_size=batch_size,\n",
    "\t\tepochs=epoch,\n",
    "\t\t# callbacks=callbacks_list,\n",
    "\t\tverbose=1)\n",
    "\tprint(H)\n",
    "# model.save(base_output+\"/cnn_dense_9000.h5\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] saving object detector model...\")\n",
    "model.save(base_output+\"/cnn_dense_9000.h5\", save_format=\"h5\")\n",
    "N = epoch\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"IoU loss on Training Set\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(base_output+\"/cnn_dense_9000.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = epoch\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"mean_average_precision\"], label=\"train_accuracy\")\n",
    "plt.title(\"Mean Average Precison\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"mAP\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(base_output+\"/cnn_dense_9000_acc.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN DENSE 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=cnn_dense_2()\n",
    "model.compile(optimizer='adam', loss=combined_loss, metrics=['Accuracy'] )\n",
    "with tf.device(\"/gpu:0\"):\n",
    "\tH = model.fit(\n",
    "\t\ttrainData, trainTargets,\n",
    "\t\tbatch_size=batch_size,\n",
    "\t\tepochs=epoch,\n",
    "\t\tverbose=1)\n",
    "\tprint(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] saving object detector model...\")\n",
    "model.save(base_output+\"/cnn_dense_2_iou.h5\", save_format=\"h5\")\n",
    "N = epoch\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.title(\"L2 + GIoU loss on Training Set\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(base_output+\"/cnn_dense_2_iou.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model(base_output+\"/cnn_dense_New_9000.h5\", compile=False)\n",
    "pred=[]\n",
    "gd=[]\n",
    "for i,img in enumerate(trainFilenames):\n",
    "    if i==500:\n",
    "        break\n",
    "    audioPath1=os.path.sep.join([audio_path, img[0]])\n",
    "    audioPath2=os.path.sep.join([audio_path, img[1]])\n",
    "    channel1,sample_rate=librosa.load(audioPath1,sr=48000)\n",
    "    channel2,sample_rate=librosa.load(audioPath2,sr=48000)\n",
    "\n",
    "    frequency,time,spectrum1=signal.spectrogram(channel1,nfft=window_size,fs=sample_rate,window=wd,noverlap=overlap,mode='magnitude')\n",
    "    frequency,time,spectrum2=signal.spectrogram(channel2,nfft=window_size,fs=sample_rate,window=wd,noverlap=overlap,mode='magnitude')\n",
    "    spectrum1=np.expand_dims(spectrum1,axis=0)\n",
    "    spectrum2=np.expand_dims(spectrum2,axis=0)\n",
    "    spectrogram=np.stack((spectrum1,spectrum2),axis=-1)\n",
    "\n",
    "    # normalize\n",
    "    min=spectrogram.min()\n",
    "    max=spectrogram.max()\n",
    "    spectrogram= (spectrogram-min)/(max-min)\n",
    "    preds = model.predict(spectrogram)[0]\n",
    "    (startX, startY, endX, endY) = preds\n",
    "    startX,endX=startX*1920, endX*1920\n",
    "    startY,endY=startY*1080, endY*1080\n",
    "    width=endX-startX\n",
    "    height=endY-startY\n",
    "    f=open(\"/home/neel/Acoustic/Acoustics/dataset2/labels/\"+img[0][9:-4]+\".txt\")\n",
    "    ground_truth=f.read().replace('\\n','').split(\" \")\n",
    "    ground_startX=float(ground_truth[1])\n",
    "    ground_startY=float(ground_truth[2])\n",
    "    ground_width=(float(ground_truth[3])-ground_startX)\n",
    "    ground_height=(float(ground_truth[4])-ground_startY)\n",
    "    print(\"Image name: \",img[0])\n",
    "    print(\"Ground truth: \",ground_startX,ground_startY,ground_width,ground_height)\n",
    "    print(\"Predicted: \",startX, startY, width, height)\n",
    "    pred.append([startX,startY,endX,endY])\n",
    "    gd.append([ground_startX,ground_startY,float(ground_truth[3]),float(ground_truth[4])])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import patches\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "startX,startY, width, height= 510.322265625, 503.85673999786377 ,315.5558395385742 ,179.6698522567749\n",
    "X,Y,W,H=571.0 ,524.0, 189.0 ,98.0\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "\n",
    "image = plt.imread('/home/neel/Acoustic/yolov5_training/img_data/frames/new_video249_8.jpg')\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "rect = patches.Rectangle((startX,startY), width, height, edgecolor='r', facecolor='none')\n",
    "rect2 = patches.Rectangle((X,Y),W,H, edgecolor='g', facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "ax.add_patch(rect2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startX,startY, width, height= 547.1884059906006, 368.9298355579376, 184.8526096343994, 127.15006470680237\n",
    "X,Y,W,H=481.99968, 332.4996 ,168.00048 ,96.999984\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "\n",
    "image = plt.imread('/home/neel/Acoustic/yolov5_training/img_data/frames/3m_train16_15.jpg')\n",
    "plt.imshow(image)\n",
    "rect = patches.Rectangle((startX,startY), width, height, edgecolor='r', facecolor='none')\n",
    "rect2 = patches.Rectangle((397,284),169,97, edgecolor='g', facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "ax.add_patch(rect2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pred)\n",
    "# print(gd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_average_precision(pred,gd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "1e7274ed0f6198f0b80ec6c61f69697cbc6657ab90adeb9c17021c87e139f38f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
