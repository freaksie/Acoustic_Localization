{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from collections import Counter\n",
    "from tensorflow.python.client import device_lib\n",
    "from keras.optimizers import Adam, Adamax, SGD\n",
    "import imutils\n",
    "import tensorflow_addons as tfa\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "<tensorflow.python.eager.context._EagerDeviceContext object at 0x7f2c98fa67c0>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.context._EagerDeviceContext at 0x7f2b8c3e3780>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
    "gpu = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu[0], True)\n",
    "print(gpu)\n",
    "tf.keras.backend.clear_session()\n",
    "TF_ENABLE_ONEDNN_OPTS=0\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(tf.device('/gpu:0'))\n",
    "\n",
    "tf.device('/gpu:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path=\"/home/neel/Acoustic/Acoustics/dataset2\"\n",
    "audio_path=os.path.sep.join([base_path,\"datachunks\"])\n",
    "annots_path=os.path.sep.join([base_path,\"train.csv\"])\n",
    "\n",
    "base_output=\"/home/neel/Acoustic/Acoustics/output3.0\"\n",
    "test_file=os.path.sep.join([base_output,\"test.txt\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Spectrograms and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading dataset...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading dataset...\")\n",
    "rows = open(annots_path).read().strip().split(\"\\n\")\n",
    "spectrogram=np.empty(((len(rows)),257,273,2), dtype=\"float32\")\n",
    "bounding_box_cords=[]\n",
    "window_size=int(512)\n",
    "wd = signal.windows.hamming(window_size)\n",
    "slide_size = int(4)\n",
    "overlap = window_size - slide_size\n",
    "filenames=[]\n",
    "cnt=0\n",
    "for row in rows:\n",
    "    # print(cnt)\n",
    "    row = row.split(\",\")\n",
    "    (filename1,filename2,X1, Y1, X2, Y2) = row\n",
    "    channel1_Path = os.path.sep.join([audio_path, filename1])\n",
    "    channel2_path = os.path.sep.join([audio_path, filename2])\n",
    "    \n",
    "    channel1,sample_rate=librosa.load(channel1_Path,sr=48000)\n",
    "    channel2,sample_rate=librosa.load(channel2_path,sr=48000)\n",
    "\n",
    "    frequency,time,spectrum1=signal.spectrogram(channel1,nfft=window_size,fs=sample_rate,window=wd,noverlap=overlap,mode='magnitude')\n",
    "    frequency,time,spectrum2=signal.spectrogram(channel2,nfft=window_size,fs=sample_rate,window=wd,noverlap=overlap,mode='magnitude')\n",
    "\n",
    "    # print(image1.shape)\n",
    "    data=np.stack((spectrum1,spectrum2),axis=-1)\n",
    "    spectrogram[cnt]=data\n",
    "    del data,frequency,time\n",
    "    cnt+=1\n",
    "    bounding_box_cords.append((X1, Y1, X2, Y2))\n",
    "    filenames.append([filename1,filename2])\n",
    "    # filenames.append(filename1)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 0.000, Max: 0.036\n",
      "Min: 0.000, Max: 1.000\n"
     ]
    }
   ],
   "source": [
    "print('Min: %.3f, Max: %.3f' % (spectrogram.min(), spectrogram.max()))\n",
    "for i in range(8831):\n",
    "    min=spectrogram[i].min()\n",
    "    max=spectrogram[i].max()\n",
    "    spectrogram[i]= (spectrogram[i]-min)/(max-min)\n",
    "\n",
    "\n",
    "print('Min: %.3f, Max: %.3f' % (spectrogram.min(), spectrogram.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel1,channel2,rows,spectrum1,spectrum2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14132, 4)\n",
      "(14132, 257, 273, 2)\n"
     ]
    }
   ],
   "source": [
    "targets = np.array(bounding_box_cords, dtype=\"float32\")\n",
    "print(targets.shape)\n",
    "print(spectrogram.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train - Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] saving testing filenames...\n",
      "Training examples:  (12718, 257, 273, 2)\n",
      "Testing examples:  (1414, 257, 273, 2)\n"
     ]
    }
   ],
   "source": [
    "split = train_test_split(spectrogram, targets, filenames, test_size=0.10,random_state=42)\n",
    "del spectrogram, targets, filenames\n",
    "(trainData, testData) = split[:2]\n",
    "(trainTargets, testTargets) = split[2:4]\n",
    "(trainFilenames, testFilenames) = split[4:]\n",
    "del split\n",
    "\n",
    "print(\"[INFO] saving testing filenames...\")\n",
    "f = open(test_file, \"w\")\n",
    "for i in testFilenames:\n",
    "    f.write(i[0]+\",\"+i[1])\n",
    "    f.write(\"\\n\")\n",
    "# f.write(\"\\n\".join(testFilenames))\n",
    "f.close()\n",
    "\n",
    "print(\"Training examples: \",trainData.shape)\n",
    "print(\"Testing examples: \",testData.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 12:04:48.605404: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-06 12:04:50.412332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 45115 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:19:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 257, 273, 64)      1216      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 257, 273, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 128, 136, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 128, 136, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 128, 136, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 64, 68, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 64, 68, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 64, 68, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 64, 68, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 32, 34, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 32, 34, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 32, 34, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 32, 34, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 16, 17, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 16, 17, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 16, 17, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 16, 17, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32768)             0         \n",
      "                                                                 \n",
      " fc_1 (Dense)                (None, 4096)              134221824 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " fc_2 (Dense)                (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " fc_3 (Dense)                (None, 1024)              4195328   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " fc_4 (Dense)                (None, 64)                65600     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 169,978,436\n",
      "Trainable params: 169,978,436\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 257, 273, 64)      1216      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 257, 273, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 128, 136, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 128, 136, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 128, 136, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 64, 68, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 64, 68, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 64, 68, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 64, 68, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 32, 34, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 32, 34, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 32, 34, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 32, 34, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 16, 17, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 16, 17, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 16, 17, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 16, 17, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32768)             0         \n",
      "                                                                 \n",
      " fc_1 (Dense)                (None, 4096)              134221824 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " fc_2 (Dense)                (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " fc_3 (Dense)                (None, 1024)              4195328   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " fc_4 (Dense)                (None, 64)                65600     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 169,978,436\n",
      "Trainable params: 169,978,436\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def vgg():\n",
    "    model = tf.keras.Sequential()\n",
    "    # Block 1\n",
    "    model.add(tf.keras.layers.Conv2D(64,(3,3), activation='relu', padding='same', name=\"block1_conv1\", input_shape=(257,273,2)))\n",
    "    model.add(tf.keras.layers.Conv2D(64,(3,3), activation='relu', padding='same', name=\"block1_conv2\"))\n",
    "    model.add(tf.keras.layers.MaxPool2D((2,2), strides=(2,2), name='block1_pool'))\n",
    "\n",
    "    # Block 2\n",
    "    model.add(tf.keras.layers.Conv2D(128,(3,3), activation='relu', padding='same', name=\"block2_conv1\"))\n",
    "    model.add(tf.keras.layers.Conv2D(128,(3,3), activation='relu', padding='same', name=\"block2_conv2\"))\n",
    "    model.add(tf.keras.layers.MaxPool2D((2,2), strides=(2,2), name='block2_pool'))\n",
    "\n",
    "    # Block 3\n",
    "    model.add(tf.keras.layers.Conv2D(256,(3,3), activation='relu', padding='same', name=\"block3_conv1\"))\n",
    "    model.add(tf.keras.layers.Conv2D(256,(3,3), activation='relu', padding='same', name=\"block3_conv2\"))\n",
    "    model.add(tf.keras.layers.Conv2D(256,(3,3), activation='relu', padding='same', name=\"block3_conv3\"))\n",
    "    model.add(tf.keras.layers.MaxPool2D((2,2), strides=(2,2), name='block3_pool'))\n",
    "\n",
    "    # Block 4\n",
    "    model.add(tf.keras.layers.Conv2D(512,(3,3), activation='relu', padding='same', name=\"block4_conv1\"))\n",
    "    model.add(tf.keras.layers.Conv2D(512,(3,3), activation='relu', padding='same', name=\"block4_conv2\"))\n",
    "    model.add(tf.keras.layers.Conv2D(512,(3,3), activation='relu', padding='same', name=\"block4_conv3\"))\n",
    "    model.add(tf.keras.layers.MaxPool2D((2,2), strides=(2,2), name='block4_pool'))\n",
    "\n",
    "    # Block 5\n",
    "    model.add(tf.keras.layers.Conv2D(512,(3,3), activation='relu', padding='same', name=\"block5_conv1\"))\n",
    "    model.add(tf.keras.layers.Conv2D(512,(3,3), activation='relu', padding='same', name=\"block5_conv2\"))\n",
    "    model.add(tf.keras.layers.Conv2D(512,(3,3), activation='relu', padding='same', name=\"block5_conv3\"))\n",
    "    model.add(tf.keras.layers.MaxPool2D((2,2), strides=(2,2), name='block5_pool'))\n",
    "\n",
    "    # FC \n",
    "    model.add(tf.keras.layers.Flatten(name='flatten'))\n",
    "    model.add(tf.keras.layers.Dense(4096, activation='relu', name='fc_1'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5, name='dropout_1'))\n",
    "    model.add(tf.keras.layers.Dense(4096, activation='relu', name='fc_2'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5, name='dropout_2'))\n",
    "    model.add(tf.keras.layers.Dense(1024, activation='relu', name='fc_3'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5, name='dropout_3'))\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu', name='fc_4'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5, name='dropout_4'))\n",
    "\n",
    "    # Output\n",
    "    model.add(tf.keras.layers.Dense(4, activation='relu', name='output'))\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "model=vgg()\n",
    "model.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(140322,)))\n",
    "    model.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(4, activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "# model=ANN()\n",
    "# model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cnn to dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 128, 136, 32)      608       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128, 136, 32)     128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 64, 68, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 31, 33, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 31, 33, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 15, 16, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 7, 7, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 3, 3, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 1, 1, 64)          36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 1, 1, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               8320      \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85,732\n",
      "Trainable params: 84,900\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def cnn_dense():\n",
    "    model= tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(32,(3,3), padding='valid',strides=2, input_shape=(257,273,2), activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPool2D((2,2), strides=(2,2)))\n",
    "    model.add(tf.keras.layers.Conv2D(32,(3,3), padding='valid',strides=2,activation='relu'))\n",
    "    \n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPool2D((2,2), strides=(2,2)))\n",
    "    model.add(tf.keras.layers.Conv2D(64,(3,3), padding='valid', strides=2,activation='relu'))\n",
    "    \n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPool2D((2,2), strides=(2,2)))\n",
    "    model.add(tf.keras.layers.Conv2D(64,(3,3), padding='valid',strides=2,activation='relu'))\n",
    "    \n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(128,activation='relu'))\n",
    "    \n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(64,activation='relu'))\n",
    "   \n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(32,activation='relu'))\n",
    "   \n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(4,activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "cnn_dense().summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN to Dense 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_dense_2():\n",
    "    model= tf.keras.Sequential()\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(32,(3,3), padding='valid',strides=2, input_shape=(257,273,2), activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPool2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(32,(3,3), padding='valid',strides=2,activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPool2D((2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(64,(3,3), padding='valid', strides=2,activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPool2D((2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(64,(3,3), padding='valid',strides=2,activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    \n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(128,activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(128,activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "   \n",
    "    model.add(tf.keras.layers.Dense(64,activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "   \n",
    "    model.add(tf.keras.layers.Dense(32,activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(4,activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# cnn_dense_2().summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def l2_loss_func(y_true, y_pred):\n",
    "  return K.mean(K.square(y_pred - y_true))\n",
    "\n",
    "\n",
    "def iou_loss_func(y_true, y_pred):\n",
    "  # Convert the predicted and ground truth bounding boxes to a format\n",
    "  # suitable for calculating the IOU\n",
    "  y_true = tf.convert_to_tensor(y_true, dtype=tf.float32)\n",
    "  y_pred = tf.convert_to_tensor(y_pred, dtype=tf.float32)\n",
    "\n",
    "  # Calculate the IOU between the predicted and ground truth bounding boxes\n",
    "  x1_true, y1_true, x2_true, y2_true = tf.split(y_true, 4, axis=-1)\n",
    "  x1_pred, y1_pred, x2_pred, y2_pred = tf.split(y_pred, 4, axis=-1)\n",
    "  x1_true, x2_true, x1_pred, x2_pred= x1_true*1440 , x2_true*1440, x1_pred*1440, x2_pred*1440\n",
    "  y1_true, y2_true, y1_pred, y2_pred= y1_true*1080 , y2_true*1080, y1_pred*1080, y2_pred*1080\n",
    "  area_true = (x2_true - x1_true + 1) * (y2_true - y1_true + 1)\n",
    "  area_pred = (x2_pred - x1_pred + 1) * (y2_pred - y1_pred + 1)\n",
    "  x1_true = K.maximum(x1_true, x1_pred)\n",
    "  y1_true = K.maximum(y1_true, y1_pred)\n",
    "  x2_true = K.minimum(x2_true, x2_pred)\n",
    "  y2_true = K.minimum(y2_true, y2_pred)\n",
    "  intersection = K.maximum(0.0, x2_true - x1_true + 1) * K.maximum(0.0, y2_true - y1_true + 1)\n",
    " \n",
    "  iou = intersection / (area_true + area_pred - intersection)\n",
    "  return 1-iou\n",
    "\n",
    "def GIoU_loss_func(y_true, y_pred):\n",
    "  # Convert the predicted and ground truth bounding boxes to a format\n",
    "  # suitable for calculating the IOU\n",
    "  y_true = tf.convert_to_tensor(y_true, dtype=tf.float32)\n",
    "  y_pred = tf.convert_to_tensor(y_pred, dtype=tf.float32)\n",
    "\n",
    "  # Calculate the IOU between the predicted and ground truth bounding boxes\n",
    "  x1_true, y1_true, x2_true, y2_true = tf.split(y_true, 4, axis=-1)\n",
    "  x1_pred, y1_pred, x2_pred, y2_pred = tf.split(y_pred, 4, axis=-1)\n",
    "\n",
    "  x1_true, x2_true, x1_pred, x2_pred= x1_true*1440 , x2_true*1440, x1_pred*1440, x2_pred*1440\n",
    "  y1_true, y2_true, y1_pred, y2_pred= y1_true*1080 , y2_true*1080, y1_pred*1080, y2_pred*1080\n",
    "\n",
    "  xmin_enclosing = K.minimum(x1_true, x1_pred)\n",
    "  ymin_enclosing = K.minimum(y1_true, y1_pred)\n",
    "  xmax_enclosing = K.maximum(x2_true, x2_pred)\n",
    "  ymax_enclosing = K.maximum(y2_true, y2_pred)\n",
    "  area_enclosing = (xmax_enclosing - xmin_enclosing) * (ymax_enclosing - ymin_enclosing)\n",
    "  # Area of boxes\n",
    "  area_true = (x2_true - x1_true + 1) * (y2_true - y1_true + 1)\n",
    "  area_pred = (x2_pred - x1_pred + 1) * (y2_pred - y1_pred + 1)\n",
    "\n",
    "  x1_true = K.maximum(x1_true, x1_pred)\n",
    "  y1_true = K.maximum(y1_true, y1_pred)\n",
    "  x2_true = K.minimum(x2_true, x2_pred)\n",
    "  y2_true = K.minimum(y2_true, y2_pred)\n",
    "  intersection = K.maximum(0.0, x2_true - x1_true + 1) * K.maximum(0.0, y2_true - y1_true + 1)\n",
    "  \n",
    "  # IoU\n",
    "  iou = intersection / (area_true + area_pred - intersection)\n",
    "  # calculate GIoU loss\n",
    "  giou = K.maximum(1.0 - intersection / (area_true + area_pred - intersection) - (area_enclosing - (area_true + area_pred - intersection)) / area_enclosing, 0.0)\n",
    "  \n",
    "  return K.mean(giou)\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "  # Calculate the Smooth L1 loss and IOU loss\n",
    "  l2_loss = l2_loss_func(y_true, y_pred)\n",
    "  iou_loss = iou_loss_func(y_true, y_pred)\n",
    "  # giou_loss = GIoU_loss_func(y_true,y_pred)\n",
    "  # Combine the losses with a weight\n",
    "  loss = 0 * l2_loss + 1 * iou_loss\n",
    "  return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error(y_true, y_pred):\n",
    "    y_true = tf.convert_to_tensor(y_true, dtype=tf.float32)\n",
    "    y_pred = tf.convert_to_tensor(y_pred, dtype=tf.float32)\n",
    "\n",
    "    xmin_true, ymin_true, xmax_true, ymax_true = tf.split(y_true, 4, axis=-1)\n",
    "    xmin_pred, ymin_pred, xmax_pred, ymax_pred = tf.split(y_pred, 4, axis=-1)\n",
    "\n",
    "    # calculate absolute difference between bounding boxes\n",
    "    abs_diff_xmin = K.abs(xmin_true - xmin_pred)\n",
    "    abs_diff_ymin = K.abs(ymin_true - ymin_pred)\n",
    "    abs_diff_xmax = K.abs(xmax_true - xmax_pred)\n",
    "    abs_diff_ymax = K.abs(ymax_true - ymax_pred)\n",
    "\n",
    "    # average absolute difference over the batch\n",
    "    return K.mean(abs_diff_xmin + abs_diff_ymin + abs_diff_xmax + abs_diff_ymax)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_lr=1e-4\n",
    "epoch=120\n",
    "batch_size=32\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    init_lr,\n",
    "    decay_steps=20,\n",
    "    decay_rate=0.1,\n",
    "    staircase=True)\n",
    "opt = SGD(learning_rate=lr_schedule ,momentum=0.9)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Run"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VGG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=vgg()\n",
    "model.compile(optimizer=opt, loss=combined_loss, metrics=['Accuracy'] )\n",
    "with tf.device(\"/gpu:0\"):\n",
    "\tH = model.fit(\n",
    "\t\ttrainData, trainTargets,\n",
    "\t\tvalidation_data=(testData, testTargets),\n",
    "\t\tbatch_size=batch_size,\n",
    "\t\tepochs=epoch,\n",
    "\t\tverbose=1)\n",
    "\tprint(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] saving object detector model...\")\n",
    "model.save(base_output+\"/vgg.h5\", save_format=\"h5\")\n",
    "N = epoch\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"Accuracy\"], label=\"train_loss\")\n",
    "plt.title(\"Bounding Box Regression MSE on Training Set\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(base_output+\"/vgg.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData1=trainData.reshape(trainData.shape[0],-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ANN()\n",
    "model.compile(optimizer='adam', loss=tfa.losses.GIoULoss(), metrics=['Accuracy'] )\n",
    "with tf.device(\"/gpu:0\"):\n",
    "\tH = model.fit(\n",
    "\t\ttrainData1, trainTargets,\n",
    "\t\tbatch_size=batch_size,\n",
    "\t\tepochs=epoch,\n",
    "\t\tverbose=1)\n",
    "\tprint(H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] saving object detector model...\")\n",
    "model.save(base_output+\"/ann.h5\", save_format=\"h5\")\n",
    "N = epoch\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"Accuracy\"], label=\"train_loss\")\n",
    "plt.title(\"Bounding Box Regression MSE on Training Set\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(base_output+\"/ann.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN DENSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=cnn_dense()\n",
    "model.compile(optimizer='adam', loss=combined_loss, metrics=['Accuracy'] )\n",
    "with tf.device(\"/gpu:0\"):\n",
    "\tH = model.fit(\n",
    "\t\ttrainData, trainTargets,\n",
    "\t\tvalidation_data=(testData, testTargets),\n",
    "\t\tbatch_size=batch_size,\n",
    "\t\tepochs=epoch,\n",
    "\t\tverbose=1)\n",
    "\tprint(H)\n",
    "# model.save(base_output+\"/cnn_dense_20000.h5\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] saving object detector model...\")\n",
    "model.save(base_output+\"/cnn_dense.h5\", save_format=\"h5\")\n",
    "N = epoch\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"Accuracy\"], label=\"train_accuracy\")\n",
    "plt.title(\"L2 + IoU loss on Training Set\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(base_output+\"/cnn_dense.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN DENSE 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=cnn_dense_2()\n",
    "model.compile(optimizer='adam', loss=combined_loss, metrics=['Accuracy'] )\n",
    "with tf.device(\"/gpu:0\"):\n",
    "\tH = model.fit(\n",
    "\t\ttrainData, trainTargets,\n",
    "\t\tbatch_size=batch_size,\n",
    "\t\tepochs=epoch,\n",
    "\t\tverbose=1)\n",
    "\tprint(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] saving object detector model...\")\n",
    "model.save(base_output+\"/cnn_dense_2_iou.h5\", save_format=\"h5\")\n",
    "N = epoch\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.title(\"L2 + GIoU loss on Training Set\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(base_output+\"/cnn_dense_2_iou.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 231ms/step\n",
      "Image name:  channel1_new_video286_14.wav\n",
      "Ground truth:  185.0 390.0 260.0 147.0\n",
      "Predicted:  1339.9160385131836 479.1136837005615 388.17935943603516 85.75348377227783\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Image name:  channel1_new_video466_17.wav\n",
      "Ground truth:  1430.0 528.0 490.0 194.0\n",
      "Predicted:  478.7973976135254 488.2332158088684 106.00439071655273 78.12920808792114\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Image name:  channel1_new_video252_2.wav\n",
      "Ground truth:  1171.0 491.0 194.0 95.0\n",
      "Predicted:  1070.0635528564453 499.6790277957916 222.4578094482422 78.30156683921814\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Image name:  channel1_new_video332_27.wav\n",
      "Ground truth:  262.0 432.0 590.0 199.0\n",
      "Predicted:  1756.369857788086 610.0016641616821 156.6397476196289 128.37814092636108\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Image name:  channel1_new_video38_25.wav\n",
      "Ground truth:  1220.0 613.0 251.0 125.0\n",
      "Predicted:  1394.5580291748047 1.9566301535815 97.15553283691406 11.015536459162831\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Image name:  channel1_new_video129_21.wav\n",
      "Ground truth:  172.0 647.0 179.0 96.0\n",
      "Predicted:  1598.397102355957 430.77312111854553 280.8926010131836 97.10119128227234\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Image name:  channel1_new_video299_26.wav\n",
      "Ground truth:  1630.0 346.0 258.0 131.0\n",
      "Predicted:  1758.3744049072266 233.5753494501114 154.21451568603516 125.12883245944977\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Image name:  channel1_new_video431_15.wav\n",
      "Ground truth:  180.0 617.0 480.0 192.0\n",
      "Predicted:  1590.7778549194336 289.66930389404297 280.66349029541016 118.11515092849731\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Image name:  channel1_new_video481_21.wav\n",
      "Ground truth:  907.0 945.0 371.0 135.0\n",
      "Predicted:  1079.5123672485352 481.4223575592041 221.43962860107422 73.6858606338501\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Image name:  channel1_new_video249_8.wav\n",
      "Ground truth:  571.0 524.0 189.0 98.0\n",
      "Predicted:  1467.436294555664 494.90052223205566 360.7630920410156 86.80031776428223\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Image name:  channel1_new_video139_18.wav\n",
      "Ground truth:  1002.0 480.0 172.0 82.0\n",
      "Predicted:  843.1768226623535 484.008092880249 198.86873245239258 75.35659790039062\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Image name:  channel1_new_video213_1.wav\n",
      "Ground truth:  812.0 516.0 212.0 112.0\n",
      "Predicted:  1383.204345703125 459.3997049331665 383.88004302978516 90.15460252761841\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Image name:  channel1_new_video110_7.wav\n",
      "Ground truth:  0.0 12.0 158.0 173.0\n",
      "Predicted:  1370.907325744629 411.68394684791565 372.6995086669922 99.19421553611755\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Image name:  channel1_new_video271_7.wav\n",
      "Ground truth:  531.0 156.0 141.0 91.0\n",
      "Predicted:  130.71417331695557 574.4593906402588 225.3425645828247 71.36302471160889\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Image name:  channel1_new_video145_6.wav\n",
      "Ground truth:  988.0 480.0 152.0 84.0\n",
      "Predicted:  1195.462417602539 177.04737603664398 183.8375473022461 113.23530614376068\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Image name:  channel1_new_video173_6.wav\n",
      "Ground truth:  444.0 0.0 284.0 174.0\n",
      "Predicted:  1691.6754913330078 485.16703248023987 212.61165618896484 97.14728236198425\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Image name:  channel1_new_video244_17.wav\n",
      "Ground truth:  332.0 600.0 555.0 231.0\n",
      "Predicted:  1229.4118881225586 320.7957172393799 360.0189971923828 114.0376353263855\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Image name:  channel1_new_video243_4.wav\n",
      "Ground truth:  422.0 632.0 482.0 185.0\n",
      "Predicted:  396.41947746276855 489.5615530014038 80.78802108764648 78.96843910217285\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Image name:  channel1_new_video141_22.wav\n",
      "Ground truth:  1022.0 485.0 148.0 82.0\n",
      "Predicted:  1189.0746688842773 197.80352175235748 187.4645233154297 114.43560540676117\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Image name:  channel1_new_video290_17.wav\n",
      "Ground truth:  707.0 396.0 220.0 119.0\n",
      "Predicted:  1406.374282836914 542.160165309906 370.33538818359375 104.01514291763306\n"
     ]
    }
   ],
   "source": [
    "model=load_model(base_output+\"/cnn_dense_9000.h5\", compile=False)\n",
    "for i,img in enumerate(testFilenames):\n",
    "    if i==20:\n",
    "        break\n",
    "    audioPath1=os.path.sep.join([audio_path, img[0]])\n",
    "    audioPath2=os.path.sep.join([audio_path, img[1]])\n",
    "    channel1,sample_rate=librosa.load(audioPath1,sr=48000)\n",
    "    channel2,sample_rate=librosa.load(audioPath2,sr=48000)\n",
    "\n",
    "    frequency,time,spectrum1=signal.spectrogram(channel1,nfft=window_size,fs=sample_rate,window=wd,noverlap=overlap,mode='magnitude')\n",
    "    frequency,time,spectrum2=signal.spectrogram(channel2,nfft=window_size,fs=sample_rate,window=wd,noverlap=overlap,mode='magnitude')\n",
    "    spectrum1=np.expand_dims(spectrum1,axis=0)\n",
    "    spectrum2=np.expand_dims(spectrum2,axis=0)\n",
    "    spectrogram=np.stack((spectrum1,spectrum2),axis=-1)\n",
    "\n",
    "    # normalize\n",
    "    min=spectrogram.min()\n",
    "    max=spectrogram.max()\n",
    "    spectrogram= (spectrogram-min)/(max-min)\n",
    "    preds = model.predict(spectrogram)[0]\n",
    "    (startX, startY, endX, endY) = preds\n",
    "    startX,endX=startX*1920, endX*1920\n",
    "    startY,endY=startY*1080, endY*1080\n",
    "    width=endX-startX\n",
    "    height=endY-startY\n",
    "    f=open(\"/home/neel/Acoustic/Acoustics/dataset2/labels/\"+img[0][9:-4]+\".txt\")\n",
    "    ground_truth=f.read().replace('\\n','').split(\" \")\n",
    "    ground_startX=float(ground_truth[1])\n",
    "    ground_startY=float(ground_truth[2])\n",
    "    ground_width=(float(ground_truth[3])-ground_startX)\n",
    "    ground_height=(float(ground_truth[4])-ground_startY)\n",
    "    print(\"Image name: \",img[0])\n",
    "    print(\"Ground truth: \",ground_startX,ground_startY,ground_width,ground_height)\n",
    "    print(\"Predicted: \",startX, startY, width, height)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import patches\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "startX,startY, width, height= 219.31240797042847, 514.230226278305 ,275.85835218429565, 95.19684433937073\n",
    "X,Y,W,H=56.0 ,596.0, 218.0, 110.0\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "\n",
    "image = plt.imread('/home/neel/Acoustic/yolov5_training/img_data/frames/3m_train43_9.jpg')\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "rect = patches.Rectangle((startX,startY), width, height, edgecolor='r', facecolor='none')\n",
    "rect2 = patches.Rectangle((X,Y),W,H, edgecolor='g', facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "ax.add_patch(rect2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startX,startY, width, height= 547.1884059906006, 368.9298355579376, 184.8526096343994, 127.15006470680237\n",
    "X,Y,W,H=481.99968, 332.4996 ,168.00048 ,96.999984\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "\n",
    "image = plt.imread('/home/neel/Acoustic/yolov5_training/img_data/frames/3m_train16_15.jpg')\n",
    "plt.imshow(image)\n",
    "rect = patches.Rectangle((startX,startY), width, height, edgecolor='r', facecolor='none')\n",
    "rect2 = patches.Rectangle((397,284),169,97, edgecolor='g', facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "ax.add_patch(rect2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e7274ed0f6198f0b80ec6c61f69697cbc6657ab90adeb9c17021c87e139f38f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
